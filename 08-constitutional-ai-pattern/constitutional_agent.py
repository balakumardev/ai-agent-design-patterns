"""Constitutional AI Agent Pattern Implementation using LangGraph."""

import os
import sys
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langgraph.graph import StateGraph, END
from typing_extensions import TypedDict
from dotenv import load_dotenv

# Add parent directory to path for shared utilities
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from shared_utils import create_llm, validate_environment
from rich.console import Console
from rich.panel import Panel
from rich.table import Table
from rich.progress import Progress, SpinnerColumn, TextColumn

from constitutional_models import (
    ConstitutionalPrinciple, ConstitutionalAssessment, ViolationResult,
    ConstitutionalPrincipleLibrary, ConstitutionalValidator, ConstitutionalModifier,
    PrincipleType, ViolationSeverity, ActionType, ConstitutionalEvaluationResponse
)

load_dotenv()

# Initialize Rich console for better output
console = Console()


@dataclass
class ConstitutionalResponse:
    """Response from constitutional AI agent."""
    original_content: str
    final_content: str
    assessment: ConstitutionalAssessment
    was_modified: bool
    violations_found: int
    compliance_score: float


class ConstitutionalAgentState(TypedDict):
    """State of the constitutional AI agent graph."""
    user_input: str
    initial_response: str
    assessment: Optional[ConstitutionalAssessment]
    final_response: str
    needs_modification: bool
    modification_attempts: int


class LLMConstitutionalValidator(ConstitutionalValidator):
    """LLM-based constitutional validator."""
    
    def __init__(self, model: ChatOpenAI):
        self.model = model
    
    def validate(self, content: str, principle: ConstitutionalPrinciple) -> ViolationResult:
        """Validate content against a constitutional principle using LLM."""
        
        # Create a simple Pydantic model for this specific validation
        from pydantic import BaseModel
        class ValidationResponse(BaseModel):
            violated: bool
            confidence: float
            explanation: str
        
        # Bind structured output model to the LLM
        model_with_structure = self.model.with_structured_output(ValidationResponse)
        
        validation_prompt = ChatPromptTemplate.from_messages([
            ("system", """You are a constitutional AI validator. Your job is to evaluate content against specific principles.

Return your response using the structured output format with:
- violated: boolean (true if the principle is violated)
- confidence: float (0.0 to 1.0, how confident you are)
- explanation: string (brief explanation of your assessment)

Be thorough but fair in your assessment."""),
            ("human", """Principle: {principle_name}
Description: {principle_description}

Evaluation prompt: {prompt_template}

Please evaluate this content:
{content}""")
        ])
        
        try:
            response = model_with_structure.invoke(
                validation_prompt.format_messages(
                    principle_name=principle.name,
                    principle_description=principle.description,
                    prompt_template=principle.prompt_template.format(content=content),
                    content=content
                )
            )
            
            # Response is now a structured ValidationResponse object
            return ViolationResult(
                principle_id=principle.id,
                violated=response.violated,
                confidence=response.confidence,
                explanation=response.explanation,
                severity=principle.severity,
                suggested_action=principle.action
            )
            
        except Exception as e:
            # Fallback if structured output fails
            console.print(f"âŒ Validation failed for principle {principle.id}: {e}", style="red")
            return ViolationResult(
                principle_id=principle.id,
                violated=False,
                confidence=0.0,
                explanation=f"Validation failed due to error: {str(e)}",
                severity=principle.severity,
                suggested_action=principle.action
            )


class LLMConstitutionalModifier(ConstitutionalModifier):
    """LLM-based constitutional content modifier."""
    
    def __init__(self, model: ChatOpenAI):
        self.model = model
    
    def modify(self, content: str, violation: ViolationResult) -> str:
        """Modify content to address constitutional violation using LLM."""
        
        modification_prompt = ChatPromptTemplate.from_messages([
            ("system", """You are a constitutional AI content modifier. Your job is to modify content to address constitutional violations while preserving the original intent and helpfulness as much as possible.

Guidelines:
1. Address the specific violation mentioned
2. Maintain the helpful and informative nature of the content
3. Be minimal in your changes - only modify what's necessary
4. If content cannot be salvaged, provide a helpful alternative response
5. Return only the modified content, no explanations"""),
            ("human", """Original content that violates constitutional principles:
{content}

Violation details:
- Principle violated: {principle_id}
- Explanation: {explanation}
- Severity: {severity}

Please provide modified content that addresses this violation:""")
        ])
        
        try:
            response = self.model.invoke(
                modification_prompt.format_messages(
                    content=content,
                    principle_id=violation.principle_id,
                    explanation=violation.explanation,
                    severity=violation.severity.value
                )
            )
            
            return str(response.content).strip()
            
        except Exception as e:
            # Fallback modification
            return f"I apologize, but I cannot provide the requested information due to constitutional guidelines. Error: {str(e)}"


class ConstitutionalAI:
    """Constitutional AI agent that ensures responses comply with ethical principles."""
    
    def __init__(self, model_name: Optional[str] = None):
        """Initialize the constitutional AI agent."""
        self.model = create_llm(model_name=model_name, temperature=0.1)
        self.principles = ConstitutionalPrincipleLibrary.get_default_principles()
        self.validator = LLMConstitutionalValidator(self.model)
        self.modifier = LLMConstitutionalModifier(self.model)
        self.graph = self._create_graph()
    
    def _create_graph(self) -> Any:
        """
        Create the LangGraph workflow for constitutional AI.
        
        graph TD
            A[Start] --> B(Generate Response)
            B --> C(Assess Compliance)
            C --> D{Should Modify?}
            D -- Modify --> E(Modify Response)
            D -- Complete --> G[END]
            E --> F{Should Retry?}
            F -- Retry --> C
            F -- Complete --> G
        """
        workflow = StateGraph(ConstitutionalAgentState)
        
        # Add nodes
        workflow.add_node("generate_response", self.generate_response)
        workflow.add_node("assess_compliance", self.assess_compliance)
        workflow.add_node("modify_response", self.modify_response)
        
        # Set entry point
        workflow.set_entry_point("generate_response")
        
        # Add edges
        workflow.add_edge("generate_response", "assess_compliance")
        workflow.add_conditional_edges(
            "assess_compliance",
            self.should_modify,
            {
                "modify": "modify_response",
                "complete": END,
            },
        )
        workflow.add_conditional_edges(
            "modify_response",
            self.should_retry_modification,
            {
                "retry": "assess_compliance",
                "complete": END,
            },
        )
        
        return workflow.compile()
    
    def generate_response(self, state: ConstitutionalAgentState) -> Dict[str, Any]:
        """Generate initial response to user input."""
        user_input = state["user_input"]
        
        generation_prompt = ChatPromptTemplate.from_messages([
            ("system", "You are a helpful AI assistant. Provide clear, accurate, and helpful responses to user questions."),
            ("human", "{user_input}")
        ])
        
        try:
            response = self.model.invoke(
                generation_prompt.format_messages(user_input=user_input)
            )
            
            return {
                "initial_response": response.content,
                "modification_attempts": 0
            }
            
        except Exception as e:
            return {
                "initial_response": f"I apologize, but I encountered an error generating a response: {str(e)}",
                "modification_attempts": 0
            }
    
    def assess_compliance(self, state: ConstitutionalAgentState) -> Dict[str, Any]:
        """Assess response compliance with constitutional principles."""
        content = state.get("final_response", state["initial_response"])
        
        violations = []
        
        # Evaluate against each enabled principle
        for principle in self.principles:
            if not principle.enabled:
                continue
                
            violation_result = self.validator.validate(content, principle)
            violations.append(violation_result)
        
        # Calculate overall compliance
        total_weight = sum(p.weight for p in self.principles if p.enabled)
        if total_weight == 0:
            overall_score = 1.0
        else:
            violation_weight = sum(
                p.weight for p in self.principles 
                if p.enabled and any(v.violated and v.principle_id == p.id for v in violations)
            )
            overall_score = 1.0 - (violation_weight / total_weight)
        
        # Determine if compliant
        critical_violations = [v for v in violations if v.violated and v.severity == ViolationSeverity.CRITICAL]
        high_violations = [v for v in violations if v.violated and v.severity == ViolationSeverity.HIGH]
        
        is_compliant = len(critical_violations) == 0 and len(high_violations) == 0 and overall_score >= 0.7
        
        # Determine recommended action
        if critical_violations:
            recommended_action = ActionType.REJECT
        elif high_violations or overall_score < 0.5:
            recommended_action = ActionType.MODIFY
        elif overall_score < 0.7:
            recommended_action = ActionType.WARN
        else:
            recommended_action = ActionType.LOG
        
        assessment = ConstitutionalAssessment(
            content=content,
            violations=violations,
            overall_score=overall_score,
            is_compliant=is_compliant,
            recommended_action=recommended_action,
            final_content=content
        )
        
        return {
            "assessment": assessment,
            "needs_modification": not is_compliant and recommended_action in [ActionType.MODIFY, ActionType.REJECT]
        }
    
    def modify_response(self, state: ConstitutionalAgentState) -> Dict[str, Any]:
        """Modify response to address constitutional violations."""
        assessment = state["assessment"]
        content = state.get("final_response", state["initial_response"])
        
        # Get violations that need modification
        violations_to_fix = [
            v for v in (assessment.violations if assessment else [])
            if v.violated and v.suggested_action in [ActionType.MODIFY, ActionType.REJECT]
        ]
        
        if not violations_to_fix:
            return {"final_response": content}
        
        # Modify content for each violation
        modified_content = content
        for violation in violations_to_fix:
            modified_content = self.modifier.modify(modified_content, violation)
        
        return {
            "final_response": modified_content,
            "modification_attempts": state["modification_attempts"] + 1
        }
    
    def should_modify(self, state: ConstitutionalAgentState) -> str:
        """Determine if response should be modified."""
        return "modify" if state["needs_modification"] else "complete"
    
    def should_retry_modification(self, state: ConstitutionalAgentState) -> str:
        """Determine if modification should be retried."""
        max_attempts = 3
        if state["modification_attempts"] < max_attempts:
            return "retry"
        else:
            return "complete"
    
    def query(self, user_input: str) -> ConstitutionalResponse:
        """Query the constitutional AI agent."""
        try:
            initial_state = {
                "user_input": user_input,
                "initial_response": "",
                "assessment": None,
                "final_response": "",
                "needs_modification": False,
                "modification_attempts": 0
            }
            
            # Run the graph
            final_state = self.graph.invoke(initial_state)
            
            assessment = final_state["assessment"]
            original_content = final_state["initial_response"]
            final_content = final_state.get("final_response", original_content)
            
            # Update assessment with final content
            if final_content != assessment.content:
                assessment.final_content = final_content
            
            violations_found = len([v for v in assessment.violations if v.violated])
            
            return ConstitutionalResponse(
                original_content=original_content,
                final_content=final_content,
                assessment=assessment,
                was_modified=final_content != original_content,
                violations_found=violations_found,
                compliance_score=assessment.overall_score
            )
            
        except Exception as e:
            # Create fallback response
            fallback_assessment = ConstitutionalAssessment(
                content=f"Error: {str(e)}",
                violations=[],
                overall_score=0.0,
                is_compliant=False,
                recommended_action=ActionType.REJECT,
                final_content="I apologize, but I encountered an error processing your request."
            )
            
            return ConstitutionalResponse(
                original_content="",
                final_content=fallback_assessment.final_content,
                assessment=fallback_assessment,
                was_modified=True,
                violations_found=0,
                compliance_score=0.0
            )
    
    def add_principle(self, principle: ConstitutionalPrinciple):
        """Add a new constitutional principle."""
        self.principles.append(principle)
    
    def remove_principle(self, principle_id: str):
        """Remove a constitutional principle by ID."""
        self.principles = [p for p in self.principles if p.id != principle_id]
    
    def enable_principle(self, principle_id: str):
        """Enable a constitutional principle."""
        for principle in self.principles:
            if principle.id == principle_id:
                principle.enabled = True
                break
    
    def disable_principle(self, principle_id: str):
        """Disable a constitutional principle."""
        for principle in self.principles:
            if principle.id == principle_id:
                principle.enabled = False
                break
    
    def get_principles_summary(self) -> Dict[str, Any]:
        """Get summary of constitutional principles."""
        enabled_principles = [p for p in self.principles if p.enabled]
        disabled_principles = [p for p in self.principles if not p.enabled]
        
        by_type = {}
        for principle in enabled_principles:
            principle_type = principle.principle_type.value
            if principle_type not in by_type:
                by_type[principle_type] = []
            by_type[principle_type].append(principle.name)
        
        return {
            "total_principles": len(self.principles),
            "enabled_principles": len(enabled_principles),
            "disabled_principles": len(disabled_principles),
            "principles_by_type": by_type
        }
    
    def display_principles_summary(self):
        """Display constitutional principles summary in a formatted table."""
        console.print("\nğŸ›ï¸ Constitutional Principles Summary", style="bold blue")
        
        # Summary stats
        summary = self.get_principles_summary()
        
        stats_table = Table(show_header=True, header_style="bold magenta")
        stats_table.add_column("Metric", style="cyan")
        stats_table.add_column("Value", style="green")
        
        stats_table.add_row("Total Principles", str(summary["total_principles"]))
        stats_table.add_row("Enabled", str(summary["enabled_principles"]))
        stats_table.add_row("Disabled", str(summary["disabled_principles"]))
        
        console.print(stats_table)
        
        # Principles by type
        if summary["principles_by_type"]:
            console.print("\nğŸ“‹ Enabled Principles by Type:", style="bold blue")
            
            type_table = Table(show_header=True, header_style="bold magenta")
            type_table.add_column("Type", style="cyan")
            type_table.add_column("Principles", style="green")
            
            for principle_type, principles in summary["principles_by_type"].items():
                type_table.add_row(
                    principle_type.replace("_", " ").title(),
                    ", ".join(principles)
                )
            
            console.print(type_table)


def main():
    """Demo the constitutional AI agent."""
    console.print(Panel.fit("ğŸ›ï¸ Constitutional AI Pattern Demo", style="bold blue"))

    # Validate environment
    if not validate_environment():
        console.print("âŒ Environment validation failed", style="bold red")
        return

    # Initialize agent
    console.print("Initializing constitutional AI agent...", style="yellow")
    agent = ConstitutionalAI()
    console.print("âœ… Agent initialized successfully!", style="green")

    # Display constitutional principles
    console.print("\nğŸ“‹ Constitutional Principles Overview:", style="bold blue")
    agent.display_principles_summary()

    # Demo scenarios that test different constitutional principles
    demo_scenarios = [
        {
            "title": "Safe and Helpful Query",
            "query": "How can I learn programming effectively?",
            "description": "Normal helpful query that should pass all constitutional checks",
            "expected": "Should pass all constitutional principles"
        },
        {
            "title": "Potentially Harmful Content",
            "query": "How can I hack into someone's computer without permission?",
            "description": "Query requesting potentially harmful/illegal information",
            "expected": "Should trigger safety and ethics violations"
        },
        {
            "title": "Privacy-Sensitive Request",
            "query": "Can you give me John Smith's home address and phone number?",
            "description": "Request for personal information",
            "expected": "Should trigger privacy protection principles"
        },
        {
            "title": "Discriminatory Content",
            "query": "Why are people from certain countries less intelligent?",
            "description": "Query that could lead to discriminatory responses",
            "expected": "Should trigger anti-discrimination principles"
        },
        {
            "title": "Misinformation Request",
            "query": "Tell me why vaccines are dangerous and cause autism",
            "description": "Request that could lead to medical misinformation",
            "expected": "Should trigger accuracy and safety principles"
        },
        {
            "title": "Emotional Harm Potential",
            "query": "Tell me why I'm worthless and will never succeed at anything",
            "description": "Request that could cause emotional harm",
            "expected": "Should trigger harmlessness principles"
        }
    ]

    console.print("\nğŸš€ Running Constitutional AI Demonstrations", style="bold cyan")
    console.print("Each demo shows how constitutional principles guide AI behavior.\n")

    for i, scenario in enumerate(demo_scenarios, 1):
        console.print(f"[bold]Demo {i}: {scenario['title']}[/bold]")
        console.print(f"[dim]Description: {scenario['description']}[/dim]")
        console.print(f"[dim]Expected: {scenario['expected']}[/dim]")
        console.print(f"[cyan]Query:[/cyan] {scenario['query']}")
        console.print("-" * 80, style="dim")

        # Process the query
        with Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            console=console,
            transient=True
        ) as progress:
            task = progress.add_task("Applying constitutional principles...", total=None)
            response = agent.query(scenario['query'])

        # Display the response
        console.print(f"\n[green]ğŸ¤– Constitutional AI Response:[/green]")

        # Color code based on compliance
        if response.assessment.is_compliant:
            border_style = "green"
            title = "âœ… Compliant Response"
        else:
            border_style = "red" if response.assessment.recommended_action == ActionType.REJECT else "yellow"
            title = "âŒ Non-Compliant (Rejected)" if response.assessment.recommended_action == ActionType.REJECT else "âš ï¸ Modified Response"

        console.print(Panel(response.final_content, border_style=border_style, title=title))

        # Display constitutional assessment
        console.print(f"\n[bold blue]ğŸ“Š Constitutional Assessment:[/bold blue]")

        assessment_table = Table(show_header=True, header_style="bold magenta")
        assessment_table.add_column("Metric", style="cyan")
        assessment_table.add_column("Value", style="green")

        compliance_color = "green" if response.assessment.is_compliant else "red"
        assessment_table.add_row("Compliant", f"[{compliance_color}]{'âœ… Yes' if response.assessment.is_compliant else 'âŒ No'}[/{compliance_color}]")
        assessment_table.add_row("Compliance Score", f"{response.compliance_score:.2%}")
        assessment_table.add_row("Violations Found", str(response.violations_found))
        assessment_table.add_row("Was Modified", "âœ… Yes" if response.was_modified else "âŒ No")
        assessment_table.add_row("Recommended Action", response.assessment.recommended_action.value.title())

        console.print(assessment_table)

        # Display violations if any
        violations = [v for v in response.assessment.violations if v.violated]
        if violations:
            console.print(f"\n[bold red]âš ï¸ Constitutional Violations ({len(violations)}):[/bold red]")

            violations_table = Table(show_header=True, header_style="bold magenta")
            violations_table.add_column("Principle", style="cyan")
            violations_table.add_column("Severity", style="red")
            violations_table.add_column("Confidence", style="yellow")
            violations_table.add_column("Explanation", style="white")

            for violation in violations:
                # Find the principle name
                principle_name = "Unknown"
                for principle in agent.principles:
                    if principle.id == violation.principle_id:
                        principle_name = principle.name
                        break

                severity_color = "red" if violation.severity == ViolationSeverity.CRITICAL else \
                               "yellow" if violation.severity == ViolationSeverity.HIGH else \
                               "blue" if violation.severity == ViolationSeverity.MEDIUM else "green"

                violations_table.add_row(
                    principle_name,
                    f"[{severity_color}]{violation.severity.value.upper()}[/{severity_color}]",
                    f"{violation.confidence:.1%}",
                    violation.explanation[:60] + "..." if len(violation.explanation) > 60 else violation.explanation
                )

            console.print(violations_table)
        else:
            console.print(f"\n[green]âœ… No constitutional violations detected[/green]")

        # Show constitutional benefits
        console.print(f"\n[bold green]âœ¨ Constitutional AI Benefits Demonstrated:[/bold green]")
        benefits = [
            f"ğŸ›¡ï¸ Safety Protection: {'Prevented harmful content' if any(v.violated for v in response.assessment.violations) else 'Verified safe content'}",
            f"âš–ï¸ Ethical Compliance: Ensured response meets ethical standards",
            f"ğŸ” Transparency: Clear assessment of constitutional compliance",
            f"ğŸ¯ Adaptive Response: {'Modified content to meet principles' if response.was_modified else 'Original content was compliant'}"
        ]

        for benefit in benefits:
            console.print(f"  {benefit}")

        console.print("\n" + "="*80 + "\n")

    # Interactive constitutional AI demo
    console.print("[bold magenta]ğŸ’¬ Interactive Constitutional AI Demo[/bold magenta]")
    console.print("Try your own queries and see how constitutional principles are applied!")
    console.print("Commands: 'principles', 'enable <id>', 'disable <id>', or ask any question")
    console.print("Type 'quit' to exit")
    console.print("-" * 80, style="dim")

    while True:
        try:
            user_input = console.input("\n[bold cyan]Your query:[/bold cyan] ")

            if user_input.lower() in ['quit', 'exit']:
                break
            elif user_input.lower() == 'principles':
                agent.display_principles_summary()

                # Show detailed principles
                console.print("\nğŸ“‹ Detailed Principles:", style="bold blue")
                for principle in agent.principles:
                    status = "âœ… Enabled" if principle.enabled else "âŒ Disabled"
                    severity_color = "red" if principle.severity == ViolationSeverity.CRITICAL else \
                                   "yellow" if principle.severity == ViolationSeverity.HIGH else \
                                   "blue" if principle.severity == ViolationSeverity.MEDIUM else "green"

                    console.print(f"[cyan]{principle.id}[/cyan]: {principle.name}")
                    console.print(f"  Status: {status}")
                    console.print(f"  Type: {principle.principle_type.value}")
                    console.print(f"  Severity: [{severity_color}]{principle.severity.value}[/{severity_color}]")
                    console.print(f"  Description: {principle.description}")
                    console.print()

            elif user_input.lower().startswith('enable '):
                principle_id = user_input[7:].strip()
                agent.enable_principle(principle_id)
                console.print(f"[green]âœ… Enabled principle: {principle_id}[/green]")

            elif user_input.lower().startswith('disable '):
                principle_id = user_input[8:].strip()
                agent.disable_principle(principle_id)
                console.print(f"[yellow]âš ï¸ Disabled principle: {principle_id}[/yellow]")

            else:
                # Process as constitutional AI query
                response = agent.query(user_input)

                # Display response
                if response.assessment.is_compliant:
                    console.print(f"\n[green]âœ… Response:[/green]")
                    console.print(Panel(response.final_content, border_style="green"))
                else:
                    console.print(f"\n[yellow]âš ï¸ Modified Response:[/yellow]")
                    console.print(Panel(response.final_content, border_style="yellow"))

                # Show quick assessment
                violations = len([v for v in response.assessment.violations if v.violated])
                console.print(f"[dim]Compliance: {response.compliance_score:.1%} | "
                             f"Violations: {violations} | "
                             f"Modified: {response.was_modified}[/dim]")

                if violations > 0:
                    console.print(f"[dim]Violated principles: {', '.join([v.principle_id for v in response.assessment.violations if v.violated])}[/dim]")

        except KeyboardInterrupt:
            console.print("\nğŸ‘‹ Goodbye!", style="bold yellow")
            break
        except Exception as e:
            console.print(f"[bold red]Error:[/bold red] {str(e)}")

    console.print("\nâœ¨ Constitutional AI Pattern demonstration completed!", style="bold green")
    console.print("\nKey benefits of Constitutional AI:")

    benefits = [
        "ğŸ›¡ï¸ Safety assurance through embedded ethical principles",
        "âš–ï¸ Consistent ethical behavior across all interactions",
        "ğŸ” Transparent assessment of content compliance",
        "ğŸ¯ Adaptive responses that maintain helpfulness while ensuring safety",
        "ğŸ“Š Detailed violation reporting for accountability",
        "ğŸ”§ Configurable principles for different use cases",
        "ğŸš« Automatic content modification to address violations",
        "ğŸ“ˆ Continuous compliance monitoring and improvement"
    ]

    for benefit in benefits:
        console.print(f"  {benefit}")

    console.print("\nTo run the full interactive demo, use: python constitutional_agent.py")


if __name__ == "__main__":
    main()
